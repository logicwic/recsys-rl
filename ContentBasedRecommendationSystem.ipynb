{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install pytorch_ranger\n",
        "# some forked from Github: /shashist/recsys-rl \n",
        "# Deep Reinforcement Learning for List-wise Recommendations Reimplementation"
      ],
      "metadata": {
        "id": "RsB_O3PMhcrY"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "WBbEvG1aixZo"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "import os\n",
        "import pickle\n",
        "import random\n",
        "import requests\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "from IPython.core.debugger import set_trace\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pytorch_ranger import Ranger\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import torch.utils.data as td\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import torch.utils.data as td\n",
        "\n",
        "#https://github.com/vitchyr/rlkit/blob/master/rlkit/exploration_strategies/ou_strategy.py\n",
        "class OUNoise(object):\n",
        "    def __init__(self, action_dim, mu=0.0, theta=0.15, max_sigma=0.4, min_sigma=0.4, decay_period=100000):\n",
        "        self.mu           = mu\n",
        "        self.theta        = theta\n",
        "        self.sigma        = max_sigma\n",
        "        self.max_sigma    = max_sigma\n",
        "        self.min_sigma    = min_sigma\n",
        "        self.decay_period = decay_period\n",
        "        self.action_dim   = action_dim\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.state = np.ones(self.action_dim) * self.mu\n",
        "\n",
        "    def evolve_state(self):\n",
        "        x  = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.random.randn(self.action_dim)\n",
        "        self.state = x + dx\n",
        "        return self.state\n",
        "\n",
        "    def get_action(self, action, t=0):\n",
        "        ou_state = self.evolve_state()\n",
        "        self.sigma = self.max_sigma - (self.max_sigma - self.min_sigma) * min(1.0, t / self.decay_period)\n",
        "        return torch.tensor([action + ou_state]).float()\n",
        "\n",
        "\n",
        "class Prioritized_Buffer(object):\n",
        "    def __init__(self, capacity, prob_alpha=0.6):\n",
        "        self.prob_alpha = prob_alpha\n",
        "        self.capacity   = capacity\n",
        "        self.buffer     = []\n",
        "        self.pos        = 0\n",
        "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
        "    \n",
        "    def push(self, user, memory, action, reward, next_user, next_memory, done):\n",
        "        max_prio = self.priorities.max() if self.buffer else 1.0\n",
        "        \n",
        "        if len(self.buffer) < self.capacity:\n",
        "            self.buffer.append((user, memory, action, reward, next_user, next_memory, done))\n",
        "        else:\n",
        "            self.buffer[self.pos] = (user, memory, action, reward, next_user, next_memory, done)\n",
        "        \n",
        "        self.priorities[self.pos] = max_prio\n",
        "        self.pos = (self.pos + 1) % self.capacity\n",
        "    \n",
        "    def sample(self, batch_size, beta=0.4):\n",
        "        if len(self.buffer) == self.capacity:\n",
        "            prios = self.priorities\n",
        "        else:\n",
        "            prios = self.priorities[:self.pos]\n",
        "        \n",
        "        probs  = prios ** self.prob_alpha\n",
        "        probs /= probs.sum()\n",
        "        \n",
        "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
        "        samples = [self.buffer[idx] for idx in indices]\n",
        "\n",
        "        total    = len(self.buffer)\n",
        "        weights  = (total * probs[indices]) ** (-beta)\n",
        "        weights /= weights.max()\n",
        "        weights  = np.array(weights, dtype=np.float32)\n",
        "\n",
        "        batch       = list(zip(*samples))\n",
        "        user        = np.concatenate(batch[0])\n",
        "        memory      = np.concatenate(batch[1])\n",
        "        action      = batch[2]\n",
        "        reward      = batch[3]\n",
        "        next_user   = np.concatenate(batch[4])\n",
        "        next_memory = np.concatenate(batch[5])\n",
        "        done        = batch[6]\n",
        "\n",
        "        return user, memory, action, reward, next_user, next_memory, done\n",
        "\n",
        "    def update_priorities(self, batch_indices, batch_priorities):\n",
        "        for idx, prio in zip(batch_indices, batch_priorities):\n",
        "            self.priorities[idx] = prio\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "def get_beta(idx, beta_start=0.4, beta_steps=100000):\n",
        "    return min(1.0, beta_start + idx * (1.0 - beta_start) / beta_steps)\n",
        "\n",
        "def preprocess_data(data_dir, train_rating):\n",
        "    data = pd.read_csv(os.path.join(data_dir, train_rating), \n",
        "                       sep='\\t', header=None, names=['user', 'item', 'rating'], \n",
        "                       usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.int8})\n",
        "    data = data[data['rating'] > 3][['user', 'item']]\n",
        "    user_num = data['user'].max() + 1\n",
        "    item_num = data['item'].max() + 1\n",
        "\n",
        "    train_data = data.sample(frac=0.8, random_state=16)\n",
        "    test_data = data.drop(train_data.index).values.tolist()\n",
        "    train_data = train_data.values.tolist()\n",
        "\n",
        "    train_mat = defaultdict(int)\n",
        "    test_mat = defaultdict(int)\n",
        "    for user, item in train_data:\n",
        "        train_mat[user, item] = 1.0\n",
        "    for user, item in test_data:\n",
        "        test_mat[user, item] = 1.0\n",
        "    train_matrix = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "    dict.update(train_matrix, train_mat)\n",
        "    test_matrix = sp.dok_matrix((user_num, item_num), dtype=np.float32)\n",
        "    dict.update(test_matrix, test_mat)\n",
        "    \n",
        "    appropriate_users = np.arange(user_num).reshape(-1, 1)[(train_matrix.sum(1) >= 20)]\n",
        "    \n",
        "    return (train_data, train_matrix, test_data, test_matrix, \n",
        "            user_num, item_num, appropriate_users)\n",
        "\n",
        "def to_np(tensor):\n",
        "    return tensor.detach().cpu().numpy()\n",
        "\n",
        "def hit_metric(recommended, actual):\n",
        "    return int(actual in recommended)\n",
        "\n",
        "def dcg_metric(recommended, actual):\n",
        "    if actual in recommended:\n",
        "        index = recommended.index(actual)\n",
        "        return np.reciprocal(np.log2(index + 2))\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EvalDataset(td.Dataset):\n",
        "    def __init__(self, positive_data, item_num, positive_mat, negative_samples=99):\n",
        "        super(EvalDataset, self).__init__()\n",
        "        self.positive_data = np.array(positive_data)\n",
        "        self.item_num = item_num\n",
        "        self.positive_mat = positive_mat\n",
        "        self.negative_samples = negative_samples\n",
        "        \n",
        "        self.reset()\n",
        "        \n",
        "    def reset(self):\n",
        "        print(\"Resetting dataset\")\n",
        "        data = self.create_valid_data()\n",
        "        labels = np.zeros(len(self.positive_data) * (1 + self.negative_samples))\n",
        "        labels[::1+self.negative_samples] = 1\n",
        "        self.data = np.concatenate([\n",
        "            np.array(data), \n",
        "            np.array(labels)[:, np.newaxis]], \n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    def create_valid_data(self):\n",
        "        valid_data = []\n",
        "        for user, positive in self.positive_data:\n",
        "            valid_data.append([user, positive])\n",
        "            for i in range(self.negative_samples):\n",
        "                negative = np.random.randint(self.item_num)\n",
        "                while (user, negative) in self.positive_mat:\n",
        "                    negative = np.random.randint(self.item_num)\n",
        "                    \n",
        "                valid_data.append([user, negative])\n",
        "        return valid_data\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user, item, label = self.data[idx]\n",
        "        output = {\n",
        "            \"user\": user,\n",
        "            \"item\": item,\n",
        "            \"label\": np.float32(label),\n",
        "        }\n",
        "        return output"
      ],
      "metadata": {
        "id": "ioJE2E03nIQl"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "code_folding": [],
        "id": "zzLNiG7BhEzp"
      },
      "outputs": [],
      "source": [
        "class State_Repr_Module(nn.Module):\n",
        "    def __init__(self, user_num, item_num, embedding_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.user_embeddings = nn.Embedding(user_num, embedding_dim)\n",
        "        self.item_embeddings = nn.Embedding(item_num+1, embedding_dim, padding_idx=int(item_num))\n",
        "        self.drr_ave = torch.nn.Conv1d(in_channels=params['N'], out_channels=1, kernel_size=1)\n",
        "                \n",
        "        self.initialize()\n",
        "            \n",
        "    def initialize(self):\n",
        "        nn.init.normal_(self.user_embeddings.weight, std=0.01)\n",
        "        nn.init.normal_(self.item_embeddings.weight, std=0.01)\n",
        "        self.item_embeddings.weight.data[-1].zero_()\n",
        "        nn.init.uniform_(self.drr_ave.weight)\n",
        "        self.drr_ave.bias.data.zero_()\n",
        "\n",
        "    def forward(self, user, memory):\n",
        "        user_embedding = self.user_embeddings(user.long())\n",
        "\n",
        "        item_embeddings = self.item_embeddings(memory.long())\n",
        "        drr_ave = self.drr_ave(item_embeddings).squeeze(1)\n",
        "        \n",
        "        return torch.cat((user_embedding, user_embedding * drr_ave, drr_ave), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "code_folding": [],
        "id": "4oYVVQLxhEzo"
      },
      "outputs": [],
      "source": [
        "class Env():\n",
        "    def __init__(self, user_item_matrix):\n",
        "        self.matrix = user_item_matrix\n",
        "        self.item_count = item_num\n",
        "        self.memory = np.ones([user_num, params['N']]) * item_num\n",
        "        # memory is initialized as [item_num] * N for each user\n",
        "        # it is padding indexes in state_repr and will result in zero embeddings\n",
        "\n",
        "    def reset(self, user_id):\n",
        "        self.user_id = user_id\n",
        "        self.viewed_items = []\n",
        "        self.related_items = np.argwhere(self.matrix[self.user_id] > 0)[:, 1]\n",
        "        self.num_rele = len(self.related_items)\n",
        "        self.nonrelated_items = np.random.choice(\n",
        "            list(set(range(self.item_count)) - set(self.related_items)), self.num_rele)\n",
        "        self.available_items = np.zeros(self.num_rele * 2)\n",
        "        self.available_items[::2] = self.related_items\n",
        "        self.available_items[1::2] = self.nonrelated_items\n",
        "        torch.Tensor()\n",
        "        return torch.tensor([self.user_id]), torch.tensor(self.memory[[self.user_id], :])\n",
        "    \n",
        "    def step(self, action, action_emb=None, buffer=None):\n",
        "        initial_user = self.user_id\n",
        "        initial_memory = self.memory[[initial_user], :]\n",
        "        \n",
        "        reward = float(to_np(action)[0] in self.related_items)\n",
        "        self.viewed_items.append(to_np(action)[0])\n",
        "        if reward:\n",
        "            if len(action) == 1:\n",
        "                self.memory[self.user_id] = list(self.memory[self.user_id][1:]) + [action]\n",
        "            else:\n",
        "                self.memory[self.user_id] = list(self.memory[self.user_id][1:]) + [action[0]]\n",
        "                \n",
        "        if len(self.viewed_items) == len(self.related_items):\n",
        "            done = 1\n",
        "        else:\n",
        "            done = 0\n",
        "            \n",
        "        if buffer is not None:\n",
        "            buffer.push(np.array([initial_user]), np.array(initial_memory), to_np(action_emb)[0], \n",
        "                        np.array([reward]), np.array([self.user_id]), self.memory[[self.user_id], :], np.array([reward]))\n",
        "\n",
        "        return torch.tensor([self.user_id]), torch.tensor(self.memory[[self.user_id], :]), reward, done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "k7YiOW9TixZs"
      },
      "outputs": [],
      "source": [
        "data_dir = \"data\"\n",
        "rating = \"ml-1m.train.rating\"\n",
        "\n",
        "params = {\n",
        "    'batch_size': 512,\n",
        "    'embedding_dim': 8,\n",
        "    'hidden_dim': 16*8,\n",
        "    'N': 5, # memory size for state_repr\n",
        "    'ou_noise':False,\n",
        "    \n",
        "    'value_lr': 1e-5,\n",
        "    'value_decay': 1e-4,\n",
        "    'policy_lr': 1e-5,\n",
        "    'policy_decay': 1e-6,\n",
        "    'state_repr_lr': 1e-5,\n",
        "    'state_repr_decay': 1e-3,\n",
        "    'log_dir': 'logs/final/',\n",
        "    'gamma': 0.8,\n",
        "    'min_value': -10,\n",
        "    'max_value': 10,\n",
        "    'soft_tau': 1e-3,\n",
        "    \n",
        "    'buffer_size': 1000000\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "code_folding": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qabQkULCixZv",
        "outputId": "eb010ec5-b70b-4f9d-bb34-a5608bb81ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skip loading data/ml-1m.train.rating\n"
          ]
        }
      ],
      "source": [
        "# Movielens (1M) data from the https://github.com/hexiangnan/neural_collaborative_filtering\n",
        "if not os.path.isdir('./data'):\n",
        "    os.mkdir('./data')\n",
        "    \n",
        "file_path = os.path.join(data_dir, rating)\n",
        "if os.path.exists(file_path):\n",
        "    print(\"Skip loading \" + file_path)\n",
        "else:\n",
        "    with open(file_path, \"wb\") as tf:\n",
        "        print(\"Load \" + file_path)\n",
        "        r = requests.get(\"https://raw.githubusercontent.com/hexiangnan/neural_collaborative_filtering/master/Data/\" + rating)\n",
        "        tf.write(r.content)\n",
        "        \n",
        "(train_data, train_matrix, test_data, test_matrix, \n",
        " user_num, item_num, appropriate_users) = preprocess_data(data_dir, rating)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "appropriate_users"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxVad1r1r5ia",
        "outputId": "2797f8eb-aadd-467f-b97b-3203ee423d56"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    1,    2, ..., 6036, 6038, 6039])"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(16)\n",
        "train_env = Env(train_matrix)\n",
        "users = np.random.permutation(appropriate_users)\n",
        "\n",
        "user, memory = train_env.reset(users[0])\n",
        "\n",
        "\n",
        "hits, dcgs = [], []\n",
        "hits_all, dcgs_all = [], []\n",
        "step, best_step = 0, 0\n",
        "step, best_step, best_step_all = 0, 0, 0\n",
        "ou_noise = OUNoise(params['embedding_dim'], decay_period=10)"
      ],
      "metadata": {
        "id": "xN4zUeuinAlN"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_repr = State_Repr_Module(user_num, item_num, params['embedding_dim'], params['hidden_dim'])"
      ],
      "metadata": {
        "id": "D8yi5Y_NrwBi"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "available_items = torch.tensor(\n",
        "                [item for item in train_env.available_items \n",
        "                if item not in train_env.viewed_items]\n",
        "            ).long()\n",
        "available_items.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuqZ5gCG87Q4",
        "outputId": "cc52e11a-dcdc-4b89-bcff-bff5e1136de6"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([124])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om3OI-tthEzn"
      },
      "source": [
        "## 1. Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdD5sTOBhEzo"
      },
      "source": [
        "- **Observation space**. As mentioned before, to get state we need `N` latest positive items (`memory`) and embedding of user. `State_Repr_Module` transform it to the vector of dimensionality `embedding_dim * 3`.\n",
        "\n",
        "- **Action space**. For every user we sample nonrelated items (the same count as related). All `available_items` which wasn't viewed before form action space.\n",
        "\n",
        "Given a state we get action embedding, compute dot product between this embedding and embeddings of all items in action space, take 1 top ranked item, compute reward, update `viewed_items` and memory, and store transition in buffer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Li8nNg-3ixZ_"
      },
      "source": [
        "## 2. Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# defining attributes for deep-Q learning\n",
        "# Source: https://github.com/ritakurban/Practical-Data-Science/blob/master/DQL_CartPole.ipynb\n",
        "\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class DQN():\n",
        "    def __init__(self, embedding_dim, hidden_dim, lr=0.05):\n",
        "        self.criterion = torch.nn.MSELoss()\n",
        "        self.model = torch.nn.Sequential(\n",
        "            nn.Linear(embedding_dim * 3, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, embedding_dim)\n",
        "        )\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr)\n",
        "\n",
        "    def update(self, state, y):\n",
        "        y_pred = self.model(torch.Tensor(state))\n",
        "        loss = self.criterion(y_pred, Variable(torch.Tensor(y)))\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        \n",
        "    def predict(self, state):\n",
        "        with torch.no_grad():\n",
        "            return self.model(torch.Tensor(state))"
      ],
      "metadata": {
        "id": "tkwphsYjw-2f"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state  = state_repr(user, memory)\n",
        "policy = DQN(params['embedding_dim'], params['hidden_dim'])"
      ],
      "metadata": {
        "id": "CCl-1Slp0JqB"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy.model.parameters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBVtJv4p4Yc6",
        "outputId": "8b37b274-897f-4291-9e63-003a39e35fae"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=24, out_features=128, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=128, out_features=8, bias=True)\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWMJnIIc3Y7i",
        "outputId": "0b0e8f2b-85b4-49a4-e5c1-e5552a1d1ddf"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user2, memory2 = train_env.reset(users[2])\n",
        "state2  = state_repr(user2, memory2)\n"
      ],
      "metadata": {
        "id": "CDjdvc6L-LTC"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user3, memory3 = train_env.reset(users[48])\n",
        "state3  = state_repr(user3, memory3)"
      ],
      "metadata": {
        "id": "UJEb9sE---Jk"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x0=policy.predict(state)\n",
        "x1=policy.predict(state2)\n",
        "x2=policy.predict(state3)"
      ],
      "metadata": {
        "id": "2tKwOq2r6WQN"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x0)\n",
        "print(x1)\n",
        "print(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLDxkp8b-uUB",
        "outputId": "b57c3ddb-11cd-4314-d428-7b16bb258cad"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0640,  0.0268, -0.0516, -0.0027, -0.0632, -0.0584,  0.0792,  0.0757]])\n",
            "tensor([[ 0.0658,  0.0287, -0.0528, -0.0029, -0.0628, -0.0558,  0.0812,  0.0737]])\n",
            "tensor([[ 0.0656,  0.0233, -0.0517, -0.0033, -0.0613, -0.0586,  0.0825,  0.0730]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "code_folding": [],
        "id": "BM1TWgxOhEzp"
      },
      "outputs": [],
      "source": [
        "# valid_dataset = EvalDataset(\n",
        "#     np.array(test_data)[np.array(test_data)[:, 0] == 6039], \n",
        "#     item_num, \n",
        "#     test_matrix)\n",
        "# valid_loader = td.DataLoader(valid_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "# full_dataset = EvalDataset(np.array(test_data), item_num, test_matrix)\n",
        "# full_loader = td.DataLoader(full_dataset, batch_size=100, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kBPbDQig_nVE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}